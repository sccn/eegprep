{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.34426573,  0.21606359, -0.02410016, ..., -0.17122105,\n",
       "          -0.17000273, -0.2128287 ]],\n",
       "\n",
       "        [[ 0.2430013 , -0.00231952, -0.24947041, ..., -0.38850403,\n",
       "          -0.35476598, -0.4007532 ]],\n",
       "\n",
       "        [[ 0.17694779, -0.08754837, -0.31283998, ..., -0.4694834 ,\n",
       "          -0.40057576, -0.4410947 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.99      , -0.99      , -0.99      , ..., -0.99      ,\n",
       "          -0.99      , -0.99      ]],\n",
       "\n",
       "        [[-0.99      , -0.99      , -0.99      , ..., -0.99      ,\n",
       "          -0.99      , -0.99      ]],\n",
       "\n",
       "        [[-0.99      , -0.99      , -0.99      , ..., -0.99      ,\n",
       "          -0.99      , -0.99      ]]]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load net_vars.mat file\n",
    "import scipy.io\n",
    "psdmed_mat = scipy.io.loadmat('net_vars.mat')['in_psdmed']\n",
    "\n",
    "psdmed_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import torch\n",
    "import scipy\n",
    "import numpy as np\n",
    "\n",
    "class Reshape(torch.nn.Module):\n",
    "        def __init__(self, shape):\n",
    "            super().__init__()\n",
    "            self.shape = shape\n",
    "\n",
    "        def forward(self, x):\n",
    "            return x.view(x.shape[0], *self.shape)\n",
    "\n",
    "class Concatenate(torch.nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "    \n",
    "    def forward(self, x: list):\n",
    "        return torch.cat(x, dim=self.dim)\n",
    "\n",
    "\n",
    "class ICLabelNet(torch.nn.Module):\n",
    "    def __init__(self, mat_path):\n",
    "        super().__init__()\n",
    "        iclabel_matlab = scipy.io.loadmat(mat_path)\n",
    "        params = iclabel_matlab['params'][0]\n",
    "        i = 11\n",
    "        print('shape of param', i, torch.tensor(params[i][1]).shape)\n",
    "        self.discriminator_image_layer1_conv = torch.nn.Conv2d(in_channels=1, out_channels=128, kernel_size=4, stride=2, padding=1, dilation=1)\n",
    "        print(self.discriminator_image_layer1_conv.weight.shape)\n",
    "        self.discriminator_image_layer1_conv.weight = torch.nn.Parameter(torch.tensor(params[0][1]).permute(3, 2, 0, 1))\n",
    "        self.discriminator_image_layer1_conv.bias = torch.nn.Parameter(torch.tensor(params[1][1]).squeeze())\n",
    "        self.discriminator_image_layer1_relu = torch.nn.ReLU()\n",
    "        self.discriminator_image_layer2_conv = torch.nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4, stride=2, padding=1, dilation=1)\n",
    "        self.discriminator_image_layer2_conv.weight = torch.nn.Parameter(torch.tensor(params[2][1]).permute(3, 2, 0, 1))\n",
    "        self.discriminator_image_layer2_conv.bias = torch.nn.Parameter(torch.tensor(params[3][1]).squeeze())\n",
    "        self.discriminator_image_layer2_relu = torch.nn.ReLU()\n",
    "        self.discriminator_image_layer3_conv = torch.nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, stride=2, padding=1, dilation=1)\n",
    "        self.discriminator_image_layer3_conv.weight = torch.nn.Parameter(torch.tensor(params[4][1]).permute(3, 2, 0, 1))\n",
    "        self.discriminator_image_layer3_conv.bias = torch.nn.Parameter(torch.tensor(params[5][1]).squeeze())\n",
    "        self.discriminator_image_layer3_relu = torch.nn.ReLU()\n",
    "        self.discriminator_psdmed_layer1_conv_conv = torch.nn.Conv2d(in_channels=1, out_channels=128, kernel_size=(1,3), stride=1, padding=(0,1), dilation=1)\n",
    "        self.discriminator_psdmed_layer1_conv_conv.weight = torch.nn.Parameter(torch.tensor(params[6][1]).permute(3, 2, 0, 1))\n",
    "        self.discriminator_psdmed_layer1_conv_conv.bias = torch.nn.Parameter(torch.tensor(params[7][1]).squeeze())\n",
    "        self.discriminator_psdmed_layer1_conv_relu = torch.nn.ReLU()\n",
    "        self.discriminator_psdmed_layer2_conv_conv = torch.nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(1,3), stride=1, padding=(0,1), dilation=1)\n",
    "        self.discriminator_psdmed_layer2_conv_conv.weight = torch.nn.Parameter(torch.tensor(params[8][1]).permute(3, 2, 0, 1))\n",
    "        self.discriminator_psdmed_layer2_conv_conv.bias = torch.nn.Parameter(torch.tensor(params[9][1]).squeeze())\n",
    "        self.discriminator_psdmed_layer2_conv_relu = torch.nn.ReLU()\n",
    "        self.discriminator_psdmed_layer3_conv_conv = torch.nn.Conv2d(in_channels=256, out_channels=1, kernel_size=(1,3), stride=1, padding=(0,1), dilation=1)\n",
    "        self.discriminator_psdmed_layer3_conv_conv.weight = torch.nn.Parameter(torch.tensor(params[10][1]).unsqueeze(3).permute(3, 2, 0, 1))\n",
    "        self.discriminator_psdmed_layer3_conv_conv.bias = torch.nn.Parameter(torch.tensor(params[11][1]).squeeze(1))\n",
    "        self.discriminator_psdmed_layer3_conv_relu = torch.nn.ReLU()\n",
    "        self.discriminator_autocorr_layer1_conv_conv = torch.nn.Conv2d(in_channels=1, out_channels=128, kernel_size=(1,3), stride=1, padding=(0,1), dilation=1)\n",
    "        self.discriminator_autocorr_layer1_conv_conv.weight = torch.nn.Parameter(torch.tensor(params[12][1]).permute(3, 2, 0, 1))\n",
    "        self.discriminator_autocorr_layer1_conv_conv.bias = torch.nn.Parameter(torch.tensor(params[13][1]).squeeze())\n",
    "        self.discriminator_autocorr_layer1_conv_relu = torch.nn.ReLU()\n",
    "        self.discriminator_autocorr_layer2_conv_conv = torch.nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(1,3), stride=1, padding=(0,1), dilation=1)\n",
    "        self.discriminator_autocorr_layer2_conv_conv.weight = torch.nn.Parameter(torch.tensor(params[14][1]).permute(3, 2, 0, 1))\n",
    "        self.discriminator_autocorr_layer2_conv_conv.bias = torch.nn.Parameter(torch.tensor(params[15][1]).squeeze())\n",
    "        self.discriminator_autocorr_layer2_conv_relu = torch.nn.ReLU()\n",
    "        self.discriminator_autocorr_layer3_conv_conv = torch.nn.Conv2d(in_channels=256, out_channels=1, kernel_size=(1,3), stride=1, padding=(0,1), dilation=1)\n",
    "        self.discriminator_autocorr_layer3_conv_conv.weight = torch.nn.Parameter(torch.tensor(params[16][1]).unsqueeze(3).permute(3, 2, 0, 1))\n",
    "        self.discriminator_autocorr_layer3_conv_conv.bias = torch.nn.Parameter(torch.tensor(params[17][1]).squeeze(1))\n",
    "        self.discriminator_autocorr_layer3_conv_relu = torch.nn.ReLU()\n",
    "        self.discriminator_psdmed_reshape = Reshape((100, 1, 1))\n",
    "        self.discriminator_psdmed_concat1 = Concatenate(dim=2)\n",
    "        self.discriminator_psdmed_concat2 = Concatenate(dim=3)\n",
    "        self.discriminator_autocorr_reshape = Reshape((100, 1, 1))\n",
    "        self.discriminator_autocorr_concat1 = Concatenate(dim=2)\n",
    "        self.discriminator_autocorr_concat2 = Concatenate(dim=3)\n",
    "        self.discriminator_concat = Concatenate(dim=1)\n",
    "        self.discriminator_conv = torch.nn.Conv2d(in_channels=712, out_channels=7, kernel_size=4, stride=1, padding=0, dilation=1)\n",
    "        self.discriminator_conv.weight = torch.nn.Parameter(torch.tensor(params[18][1]).permute(3, 2, 0, 1))\n",
    "        self.discriminator_conv.bias = torch.nn.Parameter(torch.tensor(params[19][1]).squeeze())\n",
    "        self.discriminator_softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, image, psdmed, autocorr):\n",
    "        x_image = self.discriminator_image_layer1_conv(image)\n",
    "        x_image = self.discriminator_image_layer1_relu(x_image)\n",
    "        x_image = self.discriminator_image_layer2_conv(x_image)\n",
    "        x_image = self.discriminator_image_layer2_relu(x_image)\n",
    "        x_image = self.discriminator_image_layer3_conv(x_image)\n",
    "        x_image = self.discriminator_image_layer3_relu(x_image)\n",
    "        print('x_image', x_image.shape)\n",
    "\n",
    "        x_psdmed = self.discriminator_psdmed_layer1_conv_conv(psdmed)\n",
    "        x_psdmed = self.discriminator_psdmed_layer1_conv_relu(x_psdmed)\n",
    "        x_psdmed = self.discriminator_psdmed_layer2_conv_conv(x_psdmed)\n",
    "        x_psdmed = self.discriminator_psdmed_layer2_conv_relu(x_psdmed)\n",
    "        x_psdmed = self.discriminator_psdmed_layer3_conv_conv(x_psdmed)\n",
    "        x_psdmed = self.discriminator_psdmed_layer3_conv_relu(x_psdmed)\n",
    "        x_psdmed = self.discriminator_psdmed_reshape(x_psdmed)\n",
    "        x_psdmed = self.discriminator_psdmed_concat1([x_psdmed]*4)\n",
    "        x_psdmed = self.discriminator_psdmed_concat2([x_psdmed]*4)\n",
    "        print('x_psdmed', x_psdmed.shape)\n",
    "\n",
    "        x_autocorr = self.discriminator_autocorr_layer1_conv_conv(autocorr)\n",
    "        x_autocorr = self.discriminator_autocorr_layer1_conv_relu(x_autocorr)\n",
    "        x_autocorr = self.discriminator_autocorr_layer2_conv_conv(x_autocorr)\n",
    "        x_autocorr = self.discriminator_autocorr_layer2_conv_relu(x_autocorr)\n",
    "        x_autocorr = self.discriminator_autocorr_layer3_conv_conv(x_autocorr)\n",
    "        x_autocorr = self.discriminator_autocorr_layer3_conv_relu(x_autocorr)\n",
    "        x_autocorr = self.discriminator_autocorr_reshape(x_autocorr)\n",
    "        x_autocorr = self.discriminator_autocorr_concat1([x_autocorr]*4)\n",
    "        x_autocorr = self.discriminator_autocorr_concat2([x_autocorr]*4)\n",
    "        print('x_autocorr', x_autocorr.shape)\n",
    "\n",
    "        x = self.discriminator_concat([x_image, x_psdmed, x_autocorr])\n",
    "        x = self.discriminator_conv(x)\n",
    "        print('x', x.shape)\n",
    "        x = self.discriminator_softmax(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    model = ICLabelNet('netICL.mat')\n",
    "    image_mat = scipy.io.loadmat('net_vars.mat')['in_image']\n",
    "    psdmed_mat = scipy.io.loadmat('net_vars.mat')['in_psdmed']\n",
    "    autocorr_mat = scipy.io.loadmat('net_vars.mat')['in_autocorr']\n",
    "    # assuming third dimension is trivial and last dimension is channel. First two dimensions (32 x 32) are size of topoplot\n",
    "    image = torch.tensor(image_mat).permute(-1, 2, 0, 1)\n",
    "    print('image shape', image.shape)\n",
    "    psdmed = torch.tensor(psdmed_mat).permute(-1, 2, 0, 1)\n",
    "    print('psd shape', psdmed.shape)\n",
    "    autocorr = torch.tensor(autocorr_mat).permute(-1, 2, 0, 1)\n",
    "    print('autocorr shape', autocorr.shape)\n",
    "    output = model(image, psdmed, autocorr)\n",
    "    print(output.shape)\n",
    "    \n",
    "    # save the output to a mat file\n",
    "    scipy.io.savemat('output2.mat', {'output': output.detach().numpy()})\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p311env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
