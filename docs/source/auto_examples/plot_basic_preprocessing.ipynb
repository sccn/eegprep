{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Basic EEG Preprocessing Workflow\n\nThis example demonstrates a complete EEG preprocessing workflow using eegprep,\nfollowing best practices established by leading neuroimaging packages.\n\nThe workflow includes:\n\n- Creating realistic synthetic EEG data with known characteristics\n- Applying artifact cleaning to remove transient artifacts\n- Identifying and interpolating bad channels\n- Visualizing preprocessing effects at each stage\n- Computing summary statistics to assess data quality\n\nThis example is self-contained and executable, requiring only synthetic data\ngeneration. It serves as a template for preprocessing real EEG datasets.\n\n## References\n.. [1] Delorme, A., & Makeig, S. (2004). EEGLAB: an open source toolbox for\n       analysis of single-trial EEG dynamics. Journal of Neuroscience Methods,\n       134(1), 9-21.\n.. [2] Jas, M., Engemann, D. A., Bekhti, Y., Raimondo, F., & Gramfort, A.\n       (2017). Autoreject: Automated artifact rejection for MEG and EEG data.\n       NeuroImage, 159, 417-429.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports and Setup\nImport necessary libraries for EEG processing and visualization\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\nfrom mne import create_info, EpochsArray\nfrom mne.channels import make_standard_montage\nimport sys\nsys.path.insert(0, '/Users/baristim/Projects/eegprep/src')\n\nimport eegprep\n\n# Set random seed for reproducibility\nnp.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Synthetic EEG Data\nGenerate realistic synthetic EEG data with known characteristics.\nThis data includes alpha oscillations (8-12 Hz) and background noise,\nsimulating typical resting-state EEG recordings.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define recording parameters\nn_channels = 32  # Standard 10-20 system\nn_samples = 5000  # 10 seconds at 500 Hz\nsfreq = 500  # Sampling frequency in Hz\nduration = n_samples / sfreq\n\n# Create standard 10-20 channel names\nch_names = [\n    'Fp1', 'Fpz', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8',\n    'T7', 'C3', 'Cz', 'C4', 'T8', 'P7', 'P3', 'Pz',\n    'P4', 'P8', 'O1', 'Oz', 'O2', 'A1', 'A2', 'M1',\n    'M2', 'Fc1', 'Fc2', 'Cp1', 'Cp2', 'Fc5', 'Fc6', 'Cp5'\n]\n\n# Initialize data array\ndata = np.zeros((n_channels, n_samples))\n\n# Create time vector for signal generation\nt = np.arange(n_samples) / sfreq\n\n# Generate alpha oscillations (8-12 Hz) with individual frequency variations\n# Alpha activity is a hallmark of resting-state EEG\nfor i in range(n_channels):\n    # Individual alpha frequency varies slightly across channels\n    alpha_freq = 10 + np.random.randn() * 0.5\n    # Generate sinusoidal alpha activity with amplitude ~10 \u00b5V\n    data[i, :] = 10 * np.sin(2 * np.pi * alpha_freq * t)\n    # Add background noise (typical EEG noise level ~2 \u00b5V)\n    data[i, :] += np.random.randn(n_samples) * 2\n    \n    # Introduce artifacts in specific channels to demonstrate cleaning\n    # These simulate realistic artifacts that would be removed\n    if i in [5, 15]:  # Channels Fz and Pz\n        # Add 50 Hz line noise artifact (100 ms duration)\n        data[i, 1000:1100] += 50 * np.sin(2 * np.pi * 50 * t[1000:1100])\n\n# Create MNE Info object with channel information\ninfo = create_info(ch_names=ch_names, sfreq=sfreq, ch_types='eeg')\n\n# Add standard electrode montage for spatial information\nmontage = make_standard_montage('standard_1020')\ninfo.set_montage(montage, on_missing='ignore')\n\n# Create EpochsArray (single epoch for this example)\ndata_epochs = data[np.newaxis, :, :]\nepochs = EpochsArray(data_epochs, info, events=np.array([[0, 0, 1]]), event_id=1)\n\nprint(\"=\" * 70)\nprint(\"SYNTHETIC EEG DATA CREATED\")\nprint(\"=\" * 70)\nprint(f\"Data shape: {epochs.get_data().shape}\")\nprint(f\"Number of channels: {len(epochs.ch_names)}\")\nprint(f\"Sampling rate: {epochs.info['sfreq']} Hz\")\nprint(f\"Duration: {duration:.1f} seconds\")\nprint(f\"Data range: [{np.min(data):.2f}, {np.max(data):.2f}] \u00b5V\")\nprint(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Apply Artifact Cleaning\nRemove transient artifacts using the clean_artifacts function.\nThis function identifies and removes high-amplitude transient artifacts\nwhile preserving the underlying EEG signal.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Extract raw data from epochs\nraw_data = epochs.get_data()[0]  # Shape: (n_channels, n_samples)\n\nprint(\"\\nApplying artifact cleaning...\")\nprint(\"-\" * 70)\n\n# Convert numpy array to EEG dict structure required by clean_artifacts\n# Extract channel locations from MNE info/montage\nchanlocs = []\nfor i, ch_name in enumerate(ch_names):\n    try:\n        # Get position from MNE info\n        pos = info['chs'][i]['loc'][:3]\n        if np.allclose(pos, 0):  # If position is zero/invalid, get from montage\n            pos = np.array(montage.get_pos2d([ch_name])[0]) if ch_name in montage.ch_names else np.array([0, 0])\n            # Convert 2D to 3D spherical coordinates\n            if len(pos) == 2 and not np.allclose(pos, 0):\n                x, y = pos\n                z = np.sqrt(1 - x**2 - y**2) if (x**2 + y**2) <= 1 else 0\n                pos = np.array([x, y, z])\n            elif np.allclose(pos, 0):\n                # Generate default position on unit sphere based on channel index\n                theta = (i / len(ch_names)) * 2 * np.pi\n                phi = np.pi / 4\n                pos = np.array([np.sin(phi) * np.cos(theta), np.sin(phi) * np.sin(theta), np.cos(phi)])\n    except:\n        # Default: generate position on unit sphere\n        theta = (i / len(ch_names)) * 2 * np.pi\n        phi = np.pi / 4\n        pos = np.array([np.sin(phi) * np.cos(theta), np.sin(phi) * np.sin(theta), np.cos(phi)])\n    \n    chanlocs.append({\n        'labels': ch_name,\n        'X': float(pos[0]),\n        'Y': float(pos[1]),\n        'Z': float(pos[2]),\n    })\n\nEEG_dict = {\n    'data': raw_data,\n    'srate': sfreq,\n    'nbchan': len(ch_names),\n    'pnts': raw_data.shape[1],\n    'xmin': 0,\n    'xmax': (raw_data.shape[1] - 1) / sfreq,\n    'chanlocs': chanlocs,\n    'etc': {}\n}\n\n# Apply artifact cleaning with default parameters\n# The function uses statistical criteria to identify and remove artifacts\n# Note: Disabling channel criterion and line noise check to preserve channels for visualization\nresult = eegprep.clean_artifacts(EEG_dict, ChannelCriterion='off', LineNoiseCriterion='off')\nEEG_cleaned = result[0]  # clean_artifacts returns a tuple\ncleaned_data = EEG_cleaned['data']\n\nprint(f\"Cleaned data shape: {cleaned_data.shape}\")\nprint(f\"Data range after cleaning: [{np.min(cleaned_data):.2f}, {np.max(cleaned_data):.2f}] \u00b5V\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Identify and Interpolate Bad Channels\nIdentify channels with abnormally high variance (potential bad channels)\nand perform spherical spline interpolation to recover their data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\nIdentifying bad channels...\")\nprint(\"-\" * 70)\n\n# Calculate variance for each channel\nvariances = np.var(cleaned_data, axis=1)\nmean_var = np.mean(variances)\nstd_var = np.std(variances)\n\n# Identify bad channels using statistical criterion\n# Channels with variance > mean + 2*std are considered bad\nthreshold = mean_var + 2 * std_var\nbad_channels = np.where(variances > threshold)[0]\nbad_ch_names = [ch_names[i] for i in bad_channels]\n\nprint(f\"Mean variance: {mean_var:.2f} \u00b5V\u00b2\")\nprint(f\"Std variance: {std_var:.2f} \u00b5V\u00b2\")\nprint(f\"Threshold: {threshold:.2f} \u00b5V\u00b2\")\nprint(f\"Bad channels identified: {bad_ch_names if bad_ch_names else 'None'}\")\n\n# Perform channel interpolation if bad channels are found\nif len(bad_channels) > 0:\n    print(f\"\\nInterpolating {len(bad_channels)} bad channel(s)...\")\n    # Create EEG dict for interpolation with cleaned data\n    EEG_interp_dict = {\n        'data': cleaned_data,\n        'srate': sfreq,\n        'nbchan': len(ch_names),\n        'pnts': cleaned_data.shape[1],\n        'xmin': 0,\n        'xmax': (cleaned_data.shape[1] - 1) / sfreq,\n        'chanlocs': chanlocs,\n        'etc': {}\n    }\n    EEG_interp_result = eegprep.eeg_interp(\n        EEG_interp_dict,\n        bad_chans=bad_channels\n    )\n    interpolated_data = EEG_interp_result['data']\n    print(f\"Interpolated data shape: {interpolated_data.shape}\")\nelse:\n    interpolated_data = cleaned_data\n    print(\"No bad channels to interpolate\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Preprocessing Results\nCreate comprehensive visualizations comparing original, cleaned,\nand interpolated data to assess preprocessing effects.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n\n# Select subset of channels for visualization (avoid overcrowding)\nchannels_to_plot = [0, 5, 10, 15, 20, 25]\ntime_window = slice(0, 2000)  # First 4 seconds\n\n# Plot 1: Original data with artifacts\nax = axes[0]\nfor i, ch_idx in enumerate(channels_to_plot):\n    offset = i * 30  # Vertical offset for clarity\n    ax.plot(t[time_window], raw_data[ch_idx, time_window] + offset,\n            label=ch_names[ch_idx], linewidth=1.5)\nax.set_ylabel('Amplitude (\u00b5V)', fontsize=11)\nax.set_title('Original EEG Data (with artifacts)', fontsize=12, fontweight='bold')\nax.legend(loc='upper right', fontsize=9, ncol=2)\nax.grid(True, alpha=0.3)\nax.set_xlim([t[time_window.start], t[time_window.stop-1]])\n\n# Plot 2: After artifact cleaning\nax = axes[1]\nfor i, ch_idx in enumerate(channels_to_plot):\n    offset = i * 30\n    ax.plot(t[time_window], cleaned_data[ch_idx, time_window] + offset,\n            label=ch_names[ch_idx], linewidth=1.5)\nax.set_ylabel('Amplitude (\u00b5V)', fontsize=11)\nax.set_title('After Artifact Cleaning', fontsize=12, fontweight='bold')\nax.legend(loc='upper right', fontsize=9, ncol=2)\nax.grid(True, alpha=0.3)\nax.set_xlim([t[time_window.start], t[time_window.stop-1]])\n\n# Plot 3: After channel interpolation\nax = axes[2]\nfor i, ch_idx in enumerate(channels_to_plot):\n    offset = i * 30\n    color = 'orange' if ch_idx in bad_channels else 'steelblue'\n    ax.plot(t[time_window], interpolated_data[ch_idx, time_window] + offset,\n            label=ch_names[ch_idx], linewidth=1.5, color=color)\nax.set_xlabel('Time (s)', fontsize=11)\nax.set_ylabel('Amplitude (\u00b5V)', fontsize=11)\nax.set_title('After Channel Interpolation (interpolated channels in orange)',\n             fontsize=12, fontweight='bold')\nax.legend(loc='upper right', fontsize=9, ncol=2)\nax.grid(True, alpha=0.3)\nax.set_xlim([t[time_window.start], t[time_window.stop-1]])\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary Statistics and Quality Assessment\nCompute and display summary statistics to quantify preprocessing effects\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\nprint(\"PREPROCESSING SUMMARY STATISTICS\")\nprint(\"=\" * 70)\n\n# Compute statistics for each stage\noriginal_mean = np.mean(raw_data)\noriginal_std = np.std(raw_data)\noriginal_var = np.var(raw_data)\n\ncleaned_mean = np.mean(cleaned_data)\ncleaned_std = np.std(cleaned_data)\ncleaned_var = np.var(cleaned_data)\n\ninterp_mean = np.mean(interpolated_data)\ninterp_std = np.std(interpolated_data)\ninterp_var = np.var(interpolated_data)\n\n# Display statistics table\nprint(f\"\\n{'Metric':<20} {'Original':<15} {'Cleaned':<15} {'Interpolated':<15}\")\nprint(\"-\" * 70)\nprint(f\"{'Mean (\u00b5V)':<20} {original_mean:>14.3f} {cleaned_mean:>14.3f} {interp_mean:>14.3f}\")\nprint(f\"{'Std Dev (\u00b5V)':<20} {original_std:>14.3f} {cleaned_std:>14.3f} {interp_std:>14.3f}\")\nprint(f\"{'Variance (\u00b5V\u00b2)':<20} {original_var:>14.3f} {cleaned_var:>14.3f} {interp_var:>14.3f}\")\n\n# Compute variance reduction\nvar_reduction_clean = (1 - cleaned_var / original_var) * 100\nvar_reduction_interp = (1 - interp_var / original_var) * 100\n\nprint(f\"\\n{'Variance Reduction':<20} {var_reduction_clean:>14.1f}% {var_reduction_interp:>14.1f}%\")\n\n# Channel quality summary\nprint(f\"\\n{'Total channels':<20} {n_channels}\")\nprint(f\"{'Bad channels identified':<20} {len(bad_channels)}\")\nprint(f\"{'Percentage bad':<20} {len(bad_channels)/n_channels*100:.1f}%\")\n\nprint(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Key Takeaways\nThis example demonstrates:\n\n1. **Data Generation**: Creating realistic synthetic EEG with known properties\n2. **Artifact Removal**: Identifying and removing transient artifacts\n3. **Bad Channel Detection**: Using statistical criteria to identify problematic channels\n4. **Channel Interpolation**: Recovering data from bad channels using spatial information\n5. **Quality Assessment**: Evaluating preprocessing effects through visualization and statistics\n\nFor real data, you would:\n\n- Load data from EDF, BDF, or other formats using MNE-Python\n- Apply additional preprocessing (filtering, resampling, etc.)\n- Use more sophisticated artifact detection (ICA, ASR)\n- Validate results with domain expertise\n- Document all preprocessing steps for reproducibility\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}