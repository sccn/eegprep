{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Artifact Removal Methods Comparison\n\nThis example demonstrates and compares different artifact removal methods\navailable in eegprep. Understanding the strengths and limitations of each\nmethod is crucial for effective EEG preprocessing.\n\nThe workflow includes:\n\n- Creating synthetic EEG data with realistic artifacts\n- Applying different artifact removal methods\n- Comparing results visually and statistically\n- Analyzing parameter effects on artifact removal\n- Providing recommendations for method selection\n\nThis example shows how different artifact removal strategies affect EEG data\nquality and how to choose appropriate methods for your analysis.\n\n## References\n.. [1] Jas, M., Engemann, D. A., Bekhti, Y., Raimondo, F., & Gramfort, A.\n       (2017). Autoreject: Automated artifact rejection for MEG and EEG data.\n       NeuroImage, 159, 417-429.\n.. [2] Kothe, C. A., & Makeig, S. (2013). BCILAB: a platform for brain\u2013computer\n       interface development. Journal of Neural Engineering, 10(5), 056014.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports and Setup\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\nfrom mne import create_info, EpochsArray\nfrom mne.channels import make_standard_montage\nimport sys\nsys.path.insert(0, '/Users/baristim/Projects/eegprep/src')\n\nimport eegprep\n\n# Set random seed for reproducibility\nnp.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Synthetic EEG Data with Realistic Artifacts\nGenerate EEG data containing multiple types of artifacts commonly found\nin real recordings: eye blinks, muscle activity, line noise, and drift.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Define recording parameters\nn_channels = 32\nn_samples = 10000  # 20 seconds at 500 Hz\nsfreq = 500\nduration = n_samples / sfreq\n\n# Create standard 10-20 channel names\nch_names = [\n    'Fp1', 'Fpz', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8',\n    'T7', 'C3', 'Cz', 'C4', 'T8', 'P7', 'P3', 'Pz',\n    'P4', 'P8', 'O1', 'Oz', 'O2', 'A1', 'A2', 'M1',\n    'M2', 'Fc1', 'Fc2', 'Cp1', 'Cp2', 'Fc5', 'Fc6', 'Cp5'\n]\n\n# Create time vector\nt = np.arange(n_samples) / sfreq\n\n# Initialize data with clean alpha oscillations\ndata = np.zeros((n_channels, n_samples))\n\n# Add alpha oscillations (8-12 Hz) - baseline brain activity\nfor i in range(n_channels):\n    alpha_freq = 10 + np.random.randn() * 0.5\n    data[i, :] = 10 * np.sin(2 * np.pi * alpha_freq * t)\n    # Add background noise\n    data[i, :] += np.random.randn(n_samples) * 2\n\nprint(\"=\" * 70)\nprint(\"CREATING SYNTHETIC EEG DATA WITH ARTIFACTS\")\nprint(\"=\" * 70)\n\n# Add realistic artifacts\nprint(\"\\nAdding artifacts to synthetic data...\")\n\n# 1. Eye blink artifacts (high amplitude, frontal channels, ~2 Hz)\n# Eye blinks are characterized by high amplitude, low frequency activity\n# concentrated in frontal channels\nblink_times = [1000, 3000, 5000, 7000, 9000]\nfor blink_time in blink_times:\n    window = slice(blink_time, blink_time + 200)  # ~400 ms duration\n    for i in [0, 1, 2]:  # Frontal channels (Fp1, Fpz, Fp2)\n        data[i, window] += 100 * np.sin(2 * np.pi * 2 * t[window])\nprint(f\"  \u2713 Added {len(blink_times)} eye blink artifacts\")\n\n# 2. Muscle artifacts (high frequency, temporal channels, ~30 Hz)\n# Muscle artifacts are high-frequency, high-amplitude activity\n# typically in temporal and occipital regions\nmuscle_times = [2000, 4000, 6000, 8000]\nfor muscle_time in muscle_times:\n    window = slice(muscle_time, muscle_time + 300)  # ~600 ms duration\n    for i in [8, 12]:  # Temporal channels (T7, T8)\n        data[i, window] += 50 * np.sin(2 * np.pi * 30 * t[window])\nprint(f\"  \u2713 Added {len(muscle_times)} muscle artifacts\")\n\n# 3. Line noise (50 Hz power line interference)\n# Present across all channels with consistent frequency\nfor i in range(n_channels):\n    data[i, :] += 5 * np.sin(2 * np.pi * 50 * t)\nprint(\"  \u2713 Added 50 Hz line noise across all channels\")\n\n# 4. Drift artifacts (slow baseline changes)\n# Slow drift can occur due to electrode polarization or amplifier drift\ndrift = np.linspace(0, 50, n_samples)\nfor i in range(n_channels):\n    data[i, :] += drift * (0.1 + np.random.rand())\nprint(\"  \u2713 Added slow drift artifacts\")\n\nprint(f\"\\nData with artifacts created:\")\nprint(f\"  Shape: {data.shape}\")\nprint(f\"  Range: [{np.min(data):.2f}, {np.max(data):.2f}] \u00b5V\")\nprint(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Method 1: clean_artifacts\nGeneral-purpose artifact removal using statistical criteria\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\nprint(\"METHOD 1: clean_artifacts\")\nprint(\"=\" * 70)\nprint(\"Description: General-purpose artifact removal\")\nprint(\"Removes high-amplitude transient artifacts\")\nprint(\"Good for: Eye blinks, muscle artifacts, transient noise\")\n\n# Create MNE Info object to get channel locations\ninfo = create_info(ch_names=ch_names, sfreq=sfreq, ch_types='eeg')\nmontage = make_standard_montage('standard_1020')\ninfo.set_montage(montage, on_missing='ignore')\n\n# Convert numpy array to EEG dict structure required by clean_artifacts\n# Extract channel locations from MNE info with proper coordinates\nchanlocs = []\nfor i, ch_name in enumerate(ch_names):\n    try:\n        # Get position from MNE info\n        pos = info['chs'][i]['loc'][:3]\n        if np.allclose(pos, 0):  # If position is zero/invalid, generate default\n            # Generate default position on unit sphere based on channel index\n            theta = (i / len(ch_names)) * 2 * np.pi\n            phi = np.pi / 4\n            pos = np.array([np.sin(phi) * np.cos(theta), np.sin(phi) * np.sin(theta), np.cos(phi)])\n    except:\n        # Default: generate position on unit sphere\n        theta = (i / len(ch_names)) * 2 * np.pi\n        phi = np.pi / 4\n        pos = np.array([np.sin(phi) * np.cos(theta), np.sin(phi) * np.sin(theta), np.cos(phi)])\n    \n    chanlocs.append({\n        'labels': ch_name,\n        'X': float(pos[0]),\n        'Y': float(pos[1]),\n        'Z': float(pos[2]),\n    })\n\nEEG_dict = {\n    'data': data.copy(),\n    'srate': sfreq,\n    'nbchan': len(ch_names),\n    'pnts': data.shape[1],\n    'xmin': 0,\n    'xmax': (data.shape[1] - 1) / sfreq,\n    'chanlocs': chanlocs,\n    'etc': {}\n}\n\nresult = eegprep.clean_artifacts(EEG_dict, ChannelCriterion='off', LineNoiseCriterion='off')\nEEG_result = result[0]  # clean_artifacts returns a tuple\ncleaned_artifacts = EEG_result['data']\n\nprint(f\"Result: Data range [{np.min(cleaned_artifacts):.2f}, {np.max(cleaned_artifacts):.2f}] \u00b5V\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Method 2: clean_asr (Artifact Subspace Reconstruction)\nSophisticated method that removes artifacts while preserving signal\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\nprint(\"METHOD 2: clean_asr (Artifact Subspace Reconstruction)\")\nprint(\"=\" * 70)\nprint(\"Description: Removes artifacts while preserving signal structure\")\nprint(\"Threshold controls aggressiveness (lower = more aggressive)\")\n\n# Create EEG dict for ASR (reuse the one created earlier)\ncleaned_asr_20_result = eegprep.clean_asr(\n    EEG_dict.copy(),\n    cutoff=20\n)\ncleaned_asr_20 = cleaned_asr_20_result['data']\n\ncleaned_asr_15_result = eegprep.clean_asr(\n    EEG_dict.copy(),\n    cutoff=15\n)\ncleaned_asr_15 = cleaned_asr_15_result['data']\n\nprint(f\"ASR (threshold=20): Data range [{np.min(cleaned_asr_20):.2f}, {np.max(cleaned_asr_20):.2f}] \u00b5V\")\nprint(f\"ASR (threshold=15): Data range [{np.min(cleaned_asr_15):.2f}, {np.max(cleaned_asr_15):.2f}] \u00b5V\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Method 3: clean_flatlines\nRemoves channels with no signal variation (dead channels)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\nprint(\"METHOD 3: clean_flatlines\")\nprint(\"=\" * 70)\nprint(\"Description: Removes channels with flat/dead signals\")\nprint(\"Good for: Detecting and handling non-functional channels\")\n\ncleaned_flatlines_result = eegprep.clean_flatlines(\n    EEG_dict.copy()\n)\ncleaned_flatlines = cleaned_flatlines_result['data']\n\nprint(f\"Result: Data range [{np.min(cleaned_flatlines):.2f}, {np.max(cleaned_flatlines):.2f}] \u00b5V\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Comparison: Time Domain\nCompare different methods in the time domain\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(5, 1, figsize=(14, 12))\n\n# Select channels and time window for visualization\nchannels_to_plot = [0, 8, 15]  # Frontal, temporal, parietal\ntime_window = slice(0, 3000)  # First 6 seconds\n\n# Plot 1: Original data with artifacts\nax = axes[0]\nfor i, ch_idx in enumerate(channels_to_plot):\n    offset = i * 150\n    ax.plot(t[time_window], data[ch_idx, time_window] + offset,\n            linewidth=1.5, label=ch_names[ch_idx])\nax.set_ylabel('Amplitude (\u00b5V)', fontsize=11)\nax.set_title('Original Data with Artifacts', fontsize=12, fontweight='bold')\nax.grid(True, alpha=0.3)\nax.set_xlim([t[time_window.start], t[time_window.stop-1]])\nax.legend(loc='upper right', fontsize=10)\n\n# Plot 2: clean_artifacts\nax = axes[1]\nfor i, ch_idx in enumerate(channels_to_plot):\n    offset = i * 150\n    ax.plot(t[time_window], cleaned_artifacts[ch_idx, time_window] + offset,\n            linewidth=1.5, label=ch_names[ch_idx])\nax.set_ylabel('Amplitude (\u00b5V)', fontsize=11)\nax.set_title('After clean_artifacts', fontsize=12, fontweight='bold')\nax.grid(True, alpha=0.3)\nax.set_xlim([t[time_window.start], t[time_window.stop-1]])\nax.legend(loc='upper right', fontsize=10)\n\n# Plot 3: clean_asr (threshold=20)\nax = axes[2]\nfor i, ch_idx in enumerate(channels_to_plot):\n    offset = i * 150\n    ax.plot(t[time_window], cleaned_asr_20[ch_idx, time_window] + offset,\n            linewidth=1.5, label=ch_names[ch_idx])\nax.set_ylabel('Amplitude (\u00b5V)', fontsize=11)\nax.set_title('After clean_asr (threshold=20)', fontsize=12, fontweight='bold')\nax.grid(True, alpha=0.3)\nax.set_xlim([t[time_window.start], t[time_window.stop-1]])\nax.legend(loc='upper right', fontsize=10)\n\n# Plot 4: clean_asr (threshold=15)\nax = axes[3]\nfor i, ch_idx in enumerate(channels_to_plot):\n    offset = i * 150\n    ax.plot(t[time_window], cleaned_asr_15[ch_idx, time_window] + offset,\n            linewidth=1.5, label=ch_names[ch_idx])\nax.set_ylabel('Amplitude (\u00b5V)', fontsize=11)\nax.set_title('After clean_asr (threshold=15, more aggressive)', fontsize=12, fontweight='bold')\nax.grid(True, alpha=0.3)\nax.set_xlim([t[time_window.start], t[time_window.stop-1]])\nax.legend(loc='upper right', fontsize=10)\n\n# Plot 5: clean_flatlines\nax = axes[4]\nfor i, ch_idx in enumerate(channels_to_plot):\n    offset = i * 150\n    ax.plot(t[time_window], cleaned_flatlines[ch_idx, time_window] + offset,\n            linewidth=1.5, label=ch_names[ch_idx])\nax.set_xlabel('Time (s)', fontsize=11)\nax.set_ylabel('Amplitude (\u00b5V)', fontsize=11)\nax.set_title('After clean_flatlines', fontsize=12, fontweight='bold')\nax.grid(True, alpha=0.3)\nax.set_xlim([t[time_window.start], t[time_window.stop-1]])\nax.legend(loc='upper right', fontsize=10)\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Statistical Comparison\nCompare methods using statistical metrics\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n\nmethods = ['Original', 'clean_artifacts', 'ASR (20)', 'ASR (15)', 'clean_flatlines']\ndata_arrays = [data, cleaned_artifacts, cleaned_asr_20, cleaned_asr_15, cleaned_flatlines]\ncolors = ['#d62728', '#1f77b4', '#2ca02c', '#ff7f0e', '#9467bd']\n\n# Variance comparison\nax = axes[0, 0]\nvariances = [np.var(d) for d in data_arrays]\nbars = ax.bar(methods, variances, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\nax.set_ylabel('Variance (\u00b5V\u00b2)', fontsize=11)\nax.set_title('Data Variance Comparison', fontsize=12, fontweight='bold')\nax.tick_params(axis='x', rotation=45)\nax.grid(True, alpha=0.3, axis='y')\n# Add value labels on bars\nfor bar in bars:\n    height = bar.get_height()\n    ax.text(bar.get_x() + bar.get_width()/2., height,\n            f'{height:.0f}', ha='center', va='bottom', fontsize=9)\n\n# Standard deviation comparison\nax = axes[0, 1]\nstds = [np.std(d) for d in data_arrays]\nbars = ax.bar(methods, stds, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\nax.set_ylabel('Standard Deviation (\u00b5V)', fontsize=11)\nax.set_title('Data Standard Deviation Comparison', fontsize=12, fontweight='bold')\nax.tick_params(axis='x', rotation=45)\nax.grid(True, alpha=0.3, axis='y')\nfor bar in bars:\n    height = bar.get_height()\n    ax.text(bar.get_x() + bar.get_width()/2., height,\n            f'{height:.1f}', ha='center', va='bottom', fontsize=9)\n\n# Range comparison\nax = axes[1, 0]\nranges = [np.max(d) - np.min(d) for d in data_arrays]\nbars = ax.bar(methods, ranges, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\nax.set_ylabel('Range (\u00b5V)', fontsize=11)\nax.set_title('Data Range Comparison', fontsize=12, fontweight='bold')\nax.tick_params(axis='x', rotation=45)\nax.grid(True, alpha=0.3, axis='y')\nfor bar in bars:\n    height = bar.get_height()\n    ax.text(bar.get_x() + bar.get_width()/2., height,\n            f'{height:.0f}', ha='center', va='bottom', fontsize=9)\n\n# Mean absolute value comparison\nax = axes[1, 1]\nmeans = [np.mean(np.abs(d)) for d in data_arrays]\nbars = ax.bar(methods, means, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\nax.set_ylabel('Mean Absolute Value (\u00b5V)', fontsize=11)\nax.set_title('Mean Absolute Value Comparison', fontsize=12, fontweight='bold')\nax.tick_params(axis='x', rotation=45)\nax.grid(True, alpha=0.3, axis='y')\nfor bar in bars:\n    height = bar.get_height()\n    ax.text(bar.get_x() + bar.get_width()/2., height,\n            f'{height:.1f}', ha='center', va='bottom', fontsize=9)\n\nplt.tight_layout()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary and Recommendations\nDetailed comparison and recommendations for method selection\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\nprint(\"ARTIFACT REMOVAL METHODS SUMMARY\")\nprint(\"=\" * 70)\n\nprint(\"\\n1. clean_artifacts\")\nprint(\"-\" * 70)\nprint(\"   Characteristics:\")\nprint(\"   - General-purpose artifact removal\")\nprint(\"   - Removes high-amplitude transient artifacts\")\nprint(\"   - Fast and computationally efficient\")\nprint(\"   - Good for eye blinks and muscle artifacts\")\nvar_reduction = (1 - np.var(cleaned_artifacts)/np.var(data))*100\nprint(f\"   - Variance reduction: {var_reduction:.1f}%\")\nprint(\"\\n   Best for: Quick preprocessing, real-time applications\")\n\nprint(\"\\n2. clean_asr (Artifact Subspace Reconstruction)\")\nprint(\"-\" * 70)\nprint(\"   Characteristics:\")\nprint(\"   - Removes artifacts while preserving signal structure\")\nprint(\"   - Threshold controls aggressiveness\")\nprint(\"   - More sophisticated than clean_artifacts\")\nprint(\"   - Preserves brain activity better\")\nvar_reduction_20 = (1 - np.var(cleaned_asr_20)/np.var(data))*100\nvar_reduction_15 = (1 - np.var(cleaned_asr_15)/np.var(data))*100\nprint(f\"   - ASR(20) variance reduction: {var_reduction_20:.1f}%\")\nprint(f\"   - ASR(15) variance reduction: {var_reduction_15:.1f}%\")\nprint(\"\\n   Best for: Research applications, when signal preservation is critical\")\n\nprint(\"\\n3. clean_flatlines\")\nprint(\"-\" * 70)\nprint(\"   Characteristics:\")\nprint(\"   - Removes channels with no signal variation\")\nprint(\"   - Detects dead/non-functional channels\")\nprint(\"   - Complements other methods\")\nvar_reduction_flat = (1 - np.var(cleaned_flatlines)/np.var(data))*100\nprint(f\"   - Variance reduction: {var_reduction_flat:.1f}%\")\nprint(\"\\n   Best for: Channel quality control, preprocessing pipeline\")\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"RECOMMENDATIONS\")\nprint(\"=\" * 70)\nprint(\"1. Use clean_artifacts for quick, general-purpose cleaning\")\nprint(\"2. Use clean_asr for more sophisticated artifact removal\")\nprint(\"3. Combine methods for comprehensive preprocessing\")\nprint(\"4. Always inspect results visually before and after cleaning\")\nprint(\"5. Adjust parameters based on your specific data characteristics\")\nprint(\"6. Document all preprocessing steps for reproducibility\")\nprint(\"7. Consider the trade-off between artifact removal and signal preservation\")\nprint(\"=\" * 70)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}